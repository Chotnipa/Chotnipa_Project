{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "524e2458",
   "metadata": {},
   "source": [
    "1.‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£ ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\n",
    "2.‡∏™‡∏ô‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏õ‡∏µ 2564 ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23370032",
   "metadata": {},
   "source": [
    "Web Scraping\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e85f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏µ 2564\n",
      "‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏µ 2564...\n",
      "‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏õ‡∏µ 2564\n",
      "\n",
      "üìÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏µ 2565\n",
      "‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏µ 2565...\n",
      "‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏õ‡∏µ 2565\n",
      "\n",
      "üìÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏µ 2566\n",
      "üì≠ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏µ 2566 ‚Üí ‡∏Ç‡πâ‡∏≤‡∏°\n",
      "\n",
      "üìÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏µ 2567\n",
      "üì≠ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏µ 2567 ‚Üí ‡∏Ç‡πâ‡∏≤‡∏°\n",
      "\n",
      "üìÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏µ 2568\n",
      "üì≠ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏µ 2568 ‚Üí ‡∏Ç‡πâ‡∏≤‡∏°\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# üóÇÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå\n",
    "download_dir = os.path.abspath(\"downloads\")\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# ‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "})\n",
    "\n",
    "# üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# üìÜ ‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏µ\n",
    "start_year = 2564\n",
    "end_year = datetime.datetime.now().year + 543\n",
    "\n",
    "# üîÅ ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏õ‡∏µ\n",
    "for year in range(start_year, end_year + 1):\n",
    "    print(f\"\\nüìÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏µ {year}\")\n",
    "    url = f\"https://www.nso.go.th/nsoweb/nso/statistics_and_indicators?order=&search=‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå%2F‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£+‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ+‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î&year={year}\"\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å\n",
    "\n",
    "    try:\n",
    "        # ‚è± ‡∏£‡∏≠‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏Ñ‡πà 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "        download_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"printdiv\"]/div/div[2]/div[2]/div/div/a[1]'))\n",
    "        )\n",
    "\n",
    "        # Scroll ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏¥‡∏Å‡∏î‡πâ‡∏ß‡∏¢ JS\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", download_btn)\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", download_btn)\n",
    "        print(f\"‚¨áÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏µ {year}...\")\n",
    "\n",
    "        # ‚è≥ ‡∏£‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à\n",
    "        for _ in range(15):  # ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "            if any(f.endswith(\".crdownload\") for f in os.listdir(download_dir)):\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print(f\"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏õ‡∏µ {year}\")\n",
    "\n",
    "    except Exception:\n",
    "        print(f\"üì≠ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏µ {year} ‚Üí ‡∏Ç‡πâ‡∏≤‡∏°\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd890ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥...\n",
      "üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥: 20230519191440_72558 (2).xlsx\n",
      "üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥: 20230519191440_72558 (1).xlsx\n",
      "‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ: 20230519191440_72558.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"\\nüßπ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥...\")\n",
    "\n",
    "for filename in os.listdir(download_dir):\n",
    "    if filename.endswith((\".xls\", \".xlsx\")):\n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö \"(1)\", \"(2)\", \"(3)\" ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        if re.search(r\" \\(\\d+\\)\\.xls[x]?$\", filename):\n",
    "            full_path = os.path.join(download_dir, filename)\n",
    "            os.remove(full_path)\n",
    "            print(f\"üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥: {filename}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b29d70",
   "metadata": {},
   "source": [
    "Clean Data\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå clean_data\n",
    "import os\n",
    "\n",
    "clean_dir = os.path.abspath(\"clean_data\")\n",
    "os.makedirs(clean_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c81ee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: 20230519191440_72558.xlsx\n",
      "‚úÖ ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bb/g1j94pqs6mlf7jl7kgk4kq3r0000gn/T/ipykernel_30588/2473845506.py:33: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[[\"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\", \"‡∏†‡∏≤‡∏Ñ\"]] = df[[\"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\", \"‡∏†‡∏≤‡∏Ñ\"]].fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[      region province_name            device_type  year   value\n",
       " 0    ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á   ‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£       ‡∏°‡∏µ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠  2564  755.27\n",
       " 1    ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á   ‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£            ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå  2564  287.98\n",
       " 2    ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á   ‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£  ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï  2564  736.98\n",
       " 3    ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á       ‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ       ‡∏°‡∏µ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠  2564  581.51\n",
       " 4    ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á       ‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ            ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå  2564  294.27\n",
       " ..       ...           ...                    ...   ...     ...\n",
       " 451   ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ          ‡∏¢‡∏∞‡∏•‡∏≤            ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå  2565   31.62\n",
       " 452   ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ          ‡∏¢‡∏∞‡∏•‡∏≤  ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï  2565  128.82\n",
       " 453   ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ      ‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™       ‡∏°‡∏µ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠  2565  167.52\n",
       " 454   ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ      ‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™            ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå  2565   29.48\n",
       " 455   ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ      ‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™  ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï  2565  159.73\n",
       " \n",
       " [456 rows x 5 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å downloads/ ‡πÄ‡∏Ç‡πâ‡∏≤ Pandas ‡πÅ‡∏•‡∏∞ Clean Data\n",
    "import pandas as pd\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "input_file = os.path.join(\"downloads\", \"20230519191440_72558.xlsx\")\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path\n",
    "downloads_dir = \"downloads\"\n",
    "clean_dir = \"clean_data\"\n",
    "os.makedirs(clean_dir, exist_ok=True)\n",
    "\n",
    "# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö DataFrame ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà clean ‡πÅ‡∏•‡πâ‡∏ß\n",
    "df_all = []\n",
    "\n",
    "# ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå .xlsx ‡πÉ‡∏ô downloads\n",
    "for file_name in os.listdir(downloads_dir):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(downloads_dir, file_name)\n",
    "        print(f\"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {file_name}\")\n",
    "\n",
    "        try:\n",
    "            # 1. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≤‡∏° 2 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å\n",
    "            df = pd.read_excel(file_path, skiprows=2)\n",
    "\n",
    "            # 2. Clean\n",
    "            df.columns = df.columns.map(lambda x: str(x).strip())\n",
    "            df = df.dropna(subset=[\"2564\", \"2565\"]).reset_index(drop=True)\n",
    "            df[[\"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\", \"‡∏†‡∏≤‡∏Ñ\"]] = df[[\"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\", \"‡∏†‡∏≤‡∏Ñ\"]].fillna(method='ffill')\n",
    "            df_clean = df[(df[\"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\"].notna()) & (~df[\"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\"].isin([\"‡∏£‡∏ß‡∏°\", \"‡∏ó‡∏±‡πà‡∏ß‡∏£‡∏≤‡∏ä‡∏≠‡∏≤‡∏ì‡∏≤‡∏à‡∏±‡∏Å‡∏£\"]))]\n",
    "\n",
    "            # 3. Wide ‚Üí Long\n",
    "            df_long = pd.melt(\n",
    "                df_clean,\n",
    "                id_vars=[\"‡∏†‡∏≤‡∏Ñ\", \"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\", \"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®\"],\n",
    "                value_vars=[\"2564\", \"2565\"],\n",
    "                var_name=\"year\",\n",
    "                value_name=\"value\"\n",
    "            )\n",
    "\n",
    "            df_long[\"year\"] = df_long[\"year\"].astype(int)\n",
    "            df_long[\"value\"] = pd.to_numeric(df_long[\"value\"], errors='coerce')\n",
    "\n",
    "            # 4. Rename columns\n",
    "            df_long.rename(columns={\n",
    "                \"‡∏†‡∏≤‡∏Ñ\": \"region\",\n",
    "                \"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î\": \"province_name\",\n",
    "                \"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®\": \"device_type\"\n",
    "            }, inplace=True)\n",
    "\n",
    "            # 5. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á‡πÉ‡∏ô list\n",
    "            df_all.append(df_long)\n",
    "\n",
    "            # 6. (Optional) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå clean ‡πÅ‡∏¢‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß\n",
    "            cleaned_file = os.path.join(clean_dir, f\"cleaned_{file_name}\")\n",
    "            df_long.to_excel(cleaned_file, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå {file_name}: {e}\")\n",
    "\n",
    "# 7. ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "if df_all:\n",
    "    final_df = pd.concat(df_all, ignore_index=True)\n",
    "    final_df.to_excel(os.path.join(clean_dir, \"all_cleaned_combined.xlsx\"), index=False)\n",
    "    print(\"‚úÖ ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ\")\n",
    "\n",
    "df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe8c7d",
   "metadata": {},
   "source": [
    "‡∏à‡∏≤‡∏Å local ‚Üí BigQuery \n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dddefd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‡πÅ‡∏õ‡∏•‡∏á .xlsx ‚Üí .csv`\n",
    "#BigQuery ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö .xlsx ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"clean_data/all_cleaned_combined.xlsx\")\n",
    "df.to_csv(\"clean_data/all_cleaned_combined.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90763c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Log saved to Google Sheet: monitor\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_gbq import to_gbq\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# --- CONFIG ---\n",
    "EXCEL_PATH = \"clean_data/all_cleaned_combined.xlsx\"\n",
    PROJECT_ID = "your_project_id",
    DATASET_TABLE = "your_dataset.your_table",
    GOOGLE_SHEET_ID = "your_google_sheet_id",
    SERVICE_ACCOUNT_JSON = "path_to_your_service_account.json",
    "\n",
    "# --- AUTH ---\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_JSON,\n",
    "    scopes=[\n",
    "        \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "        \"https://www.googleapis.com/auth/drive\",\n",
    "        \"https://www.googleapis.com/auth/bigquery\"\n",
    "    ]\n",
    ")\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "# --- STEP 1: Load Excel ---\n",
    "try:\n",
    "    df = pd.read_excel(EXCEL_PATH)\n",
    "\n",
    "    # --- STEP 1.5: Load current row count from BigQuery ---\n",
    "    try:\n",
    "        bq_client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
    "        query = f\"SELECT COUNT(*) AS total FROM `{DATASET_TABLE}`\"\n",
    "        old_rows = bq_client.query(query).to_dataframe().iloc[0][\"total\"]\n",
    "    except:\n",
    "        old_rows = 0  # ‡∏ñ‡πâ‡∏≤ table ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "    # --- STEP 2: Upload to BigQuery ---\n",
    "    to_gbq(\n",
    "        dataframe=df,\n",
    "        destination_table=DATASET_TABLE,\n",
    "        project_id=PROJECT_ID,\n",
    "        if_exists=\"replace\",  # ‡∏´‡∏£‡∏∑‡∏≠ \"append\" ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢\n",
    "        credentials=credentials\n",
    "    )\n",
    "\n",
    "    # --- STEP 3A: Log SUCCESS\n",
    "    log_df = pd.DataFrame([{\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"status\": \"‚úÖ SUCCESS\",\n",
    "        \"rows_uploaded\": len(df),\n",
    "        \"new_rows_added\": len(df) - old_rows,\n",
    "        \"file\": EXCEL_PATH\n",
    "    }])\n",
    "\n",
    "except Exception as e:\n",
    "    # --- STEP 3B: Log ERROR\n",
    "    log_df = pd.DataFrame([{\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"status\": f\"‚ùå ERROR: {e}\",\n",
    "        \"rows_uploaded\": 0,\n",
    "        \"new_rows_added\": 0,\n",
    "        \"file\": EXCEL_PATH\n",
    "    }])\n",
    "\n",
    "# --- STEP 4: Append log to Google Sheet\n",
    "try:\n",
    "    sh = gc.open_by_key(GOOGLE_SHEET_ID)\n",
    "    worksheet = sh.worksheet(SHEET_TAB_NAME)\n",
    "\n",
    "    existing = pd.DataFrame(worksheet.get_all_records())\n",
    "    full_log = pd.concat([existing, log_df], ignore_index=True)\n",
    "\n",
    "    worksheet.clear()\n",
    "    set_with_dataframe(worksheet, full_log)\n",
    "    print(\"‚úÖ Log saved to Google Sheet: monitor\")\n",
    "\n",
    "except Exception as log_err:\n",
    "    print(\"‚ö†Ô∏è Failed to write log to Google Sheets:\")\n",
    "    print(log_err)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
